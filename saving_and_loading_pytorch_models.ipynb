{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "saving and loading pytorch models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNDn04LuULUP"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=0)\n",
        "    self.pool1 = nn.MaxPool2d(2,2)\n",
        "    self.bn = nn.BatchNorm2d(16)\n",
        "    self.fc1 = nn.Linear(256,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=self.conv1(x)\n",
        "    x=self.pool1(x)\n",
        "    x=self.bn(x)\n",
        "    x=self.Linear(x)\n",
        "\n",
        "    return x\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5luQ1_aV8gR"
      },
      "source": [
        "my_model = model()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30hh7xORYRCG"
      },
      "source": [
        "We can save either the model archeticture + weights or just the weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpchYL6lYkfe"
      },
      "source": [
        "##Saving the archeticture + weights:\n",
        "The model is saved as pickle file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5eAPCpDVY56"
      },
      "source": [
        "model_path = 'models'\n",
        "torch.save(my_model , model_path)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVvxyA58V5yx"
      },
      "source": [
        "#to load the model use torch.load()\n",
        "#no need to define the model archeticture (object) first\n",
        "new_model = torch.load(model_path)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4auol1pZMQ-"
      },
      "source": [
        "##Saving just the model weights (state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj_QZ5QeZKyG",
        "outputId": "061e5f19-277a-48cb-d96d-3bf833521f8e"
      },
      "source": [
        "#The state_dict is a python dictionary that contains all the layers paprametars + register buffer (like BN parameters)\n",
        "for param in my_model.state_dict():\n",
        "  print(f'{param} shape {my_model.state_dict()[param].shape}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.weight shape torch.Size([16, 3, 3, 3])\n",
            "conv1.bias shape torch.Size([16])\n",
            "bn.weight shape torch.Size([16])\n",
            "bn.bias shape torch.Size([16])\n",
            "bn.running_mean shape torch.Size([16])\n",
            "bn.running_var shape torch.Size([16])\n",
            "bn.num_batches_tracked shape torch.Size([])\n",
            "fc1.weight shape torch.Size([10, 256])\n",
            "fc1.bias shape torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCy8gHTqZmN0"
      },
      "source": [
        "params_path='model_state_dict'\n",
        "torch.save(my_model.state_dict() , params_path)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bNBtueba6W9",
        "outputId": "cacaad3f-7414-4e30-a9e1-5a1e8655cae7"
      },
      "source": [
        "#We can not use torch.load() directly to load the weights!. We need to define the model archeticure first.\n",
        "#If the model matches the weights it will work well\n",
        "my_new_model = model()\n",
        "state_dict = torch.load(params_path)\n",
        "my_new_model.load_state_dict(state_dict)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4dgO4fDcMxi"
      },
      "source": [
        "##Optimizers also have parameters that we can save:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59dquF3YbZs8",
        "outputId": "ccbdc465-5fc2-4a09-b090-42219566e3d9"
      },
      "source": [
        "optimizer = torch.optim.Adam(my_model.parameters(), lr=0.003, betas=(0.9, 0.90), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "for param in optimizer.state_dict():\n",
        "  print(f'{param}    shape      {optimizer.state_dict()[param]}')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "state    shape      {}\n",
            "param_groups    shape      [{'lr': 0.003, 'betas': (0.9, 0.9), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5]}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-UXTgavgWHz"
      },
      "source": [
        "**Saving the entire optimizer object**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5aN1tSjcvzg"
      },
      "source": [
        "optimizer_path = 'adam_optimizer'\n",
        "torch.save(optimizer , optimizer_path)\n",
        "optimizer = torch.load(optimizer_path)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUob8U6Hgdhp"
      },
      "source": [
        "**Saving the optimizer state_dict:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJvRYc5kgxRc"
      },
      "source": [
        "optimizer_state_dict_path=\"adam_optimizer_state_dict\"\n",
        "torch.save(optimizer.state_dict() , optimizer_state_dict_path)\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqGRaWM3fEyV"
      },
      "source": [
        "new_optimizer = torch.optim.Adam(my_model.parameters())"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQvfFcHJf1Me",
        "outputId": "b5ab4462-6b0f-4a5e-89d8-de7b719ed347"
      },
      "source": [
        "torch.load(optimizer_state_dict_path)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'param_groups': [{'amsgrad': False,\n",
              "   'betas': (0.9, 0.9),\n",
              "   'eps': 1e-08,\n",
              "   'lr': 0.003,\n",
              "   'params': [0, 1, 2, 3, 4, 5],\n",
              "   'weight_decay': 0}],\n",
              " 'state': {}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwiMpnEpfqkk",
        "outputId": "8ba78e7a-9576-4ca2-da32-6d8e125be163"
      },
      "source": [
        "#load the optimizer state_dict\n",
        "new_optimizer.load_state_dict(torch.load(optimizer_state_dict_path))\n",
        "\n",
        "for param in new_optimizer.state_dict():\n",
        "  print(f'{param}    shape      {new_optimizer.state_dict()[param]}')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "state    shape      {}\n",
            "param_groups    shape      [{'lr': 0.003, 'betas': (0.9, 0.9), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5]}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "302bCC77dnsc"
      },
      "source": [
        "##Torch.save can save any python object!:\n",
        "We can save all our work in one ckpt file (model, optimizer, loss, epochs, ... )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqtgswLLd_Lh"
      },
      "source": [
        "path_for_all = 'all'\n",
        "epoch=8\n",
        "loss=0.022\n",
        "torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model': my_model,\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            \n",
        "            }, path_for_all)\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqESofFJeRY9"
      },
      "source": [
        "checkpoint = torch.load(path_for_all)\n",
        "model_to_continue_training = checkpoint['model']\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch=checkpoint['epoch']\n",
        "loss=checkpoint['loss']\n",
        "\n",
        "#continue training....\n",
        "#evaluate............."
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0add-hDYlA6z",
        "outputId": "caececbf-eace-4f1f-f45c-cac9c1dd7440"
      },
      "source": [
        "for param in model_to_continue_training.state_dict():\n",
        "  print(f'{param}    shape      {model_to_continue_training.state_dict()[param].shape}')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.weight    shape      torch.Size([16, 3, 3, 3])\n",
            "conv1.bias    shape      torch.Size([16])\n",
            "bn.weight    shape      torch.Size([16])\n",
            "bn.bias    shape      torch.Size([16])\n",
            "bn.running_mean    shape      torch.Size([16])\n",
            "bn.running_var    shape      torch.Size([16])\n",
            "bn.num_batches_tracked    shape      torch.Size([])\n",
            "fc1.weight    shape      torch.Size([10, 256])\n",
            "fc1.bias    shape      torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLuZ68DQj-yy",
        "outputId": "4846baf9-c721-4073-88c0-cde95f3ac4d2"
      },
      "source": [
        "for param in optimizer.state_dict():\n",
        "  print(f'{param}    shape      {optimizer.state_dict()[param]}')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "state    shape      {}\n",
            "param_groups    shape      [{'lr': 0.003, 'betas': (0.9, 0.9), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5]}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4pFEkB-kc5P",
        "outputId": "3b6c1ba4-2824-41e1-e7eb-13f0fe997993"
      },
      "source": [
        "loss"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.022"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_4VsStOk8s-",
        "outputId": "84ab92aa-b002-444e-c358-086f118ed89b"
      },
      "source": [
        "epoch"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxgeqBhmk--C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}